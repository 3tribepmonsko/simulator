//

pipeline {

  agent {
    node {
      label "unity3d-2019.3-vulkan"
      customWorkspace "/home/jenkins/workspace/simulator-cloud-release-2019.3.15f1"
    }
  }

  options {
    gitLabConnection("${GITLAB_HOST}")
    skipDefaultCheckout(true)
    timestamps()
  }

  parameters {
    string(name: "CLOUD_URL", defaultValue: "${SIMULATOR_WISE_STAGING_URL}", description: "")
    string(name: "SCENARIOS_RUNNER_DOCKER_TAG", defaultValue: "hdrp/scenarios/runner/jenkins:latest", description: "Repo and tag of scenarios runner docker image which will be bundled in zip archive")
    string(name: 'WISE_AWS_ECR_ACCOUNT_ID', defaultValue: '853285614468', description: 'The AWS account ID whose ECR will be used', trim: true)
    string(name: 'WISE_AWS_ECR_REGION', defaultValue: 'us-east-1', description: 'The AWS region where the ECR is located', trim: true)
    credentials( name: 'WISE_AWS_ECR_CREDENTIALS_ID', required: true, defaultValue: "simulator--aws-credentials", description: 'The credentials to be used for accessing the ECR', credentialType: 'com.cloudbees.jenkins.plugins.awscredentials.AWSCredentialsImpl')
  }

  environment {
    UNITY_USERNAME = credentials("UNITY_USERNAME")
    UNITY_PASSWORD = credentials("UNITY_PASSWORD")
    UNITY_SERIAL = credentials("UNITY_SERIAL")
    CODE_SIGNING_PASSWORD = credentials("LGSVL_CODE_SIGNING_PASSWORD")
    BUILD_BUNDLES = "true"
    PYTHONUNBUFFERED = "1"
    DISPLAY = ":0"
    JENKINS_BUILD_ID = "${BUILD_ID}"
    OUTPUT_SUFFIX = "${sh(script:"echo ${env.GIT_TAG} | sed 's#^refs/tags/##g' | tr / -  | tr [:upper:] [:lower:]", returnStdout: true).trim()}"
    CODE_SIGNING_FILE = "/dev/urandom"
    FORCE_REBUILD = "${FORCE_REBUILD}"
  }

  stages {
    stage("Build environment") {
        steps {
            sh label:"SIMULATOR env vars", script:"printenv | grep -E 'SIMULATOR|^SIM_' | sort"
        }
    }

    stage("Git") {
      steps {

        mail to: "${SIMULATOR_RELEASE_EMAILS}", subject: "Starting ${OUTPUT_SUFFIX} release build", body: "Starting ${OUTPUT_SUFFIX} release build: ${BUILD_URL}"

        checkout([
          $class: "GitSCM",
          branches: [[name: "refs/tags/${env.GIT_TAG}"]],
          browser: [$class: "GitLab", repoUrl: "https://${GITLAB_HOST}/HDRP/Simulator", version: env.GITLAB_VERSION],
          extensions: [
            [$class: "LocalBranch"],
            [$class: "GitLFSPull"]
          ],
          userRemoteConfigs: [[
            credentialsId: "auto-gitlab",
            url: "git@${GITLAB_HOST}:HDRP/Simulator.git"
          ]]
        ])

        sh label:"Cleanup the checkout", script:"""
            git clean -xdff .
            git reset --hard
        """

        script {

          def controllables = env.SIMULATOR_CONTROLLABLES.split(',')
          for (int i=0; i<controllables.size(); i++) {
            def controllable = controllables[i]
            checkout([
              $class: "GitSCM",
              branches: [[name: "refs/heads/master"]],
              browser: [$class: "GitLab", repoUrl: "https://${GITLAB_HOST}/HDRP/Controllables/${controllable}", version: env.GITLAB_VERSION],
              extensions: [
                [$class: "RelativeTargetDirectory", relativeTargetDir: "Assets/External/Controllables/${controllable}"],
                [$class: "LocalBranch"],
                [$class: "GitLFSPull"]
              ],
              userRemoteConfigs: [[
                credentialsId: "auto-gitlab",
                url: "git@${GITLAB_HOST}:HDRP/Controllables/${controllable}.git"
              ]]
            ])
          }

          env.FORCE_REBUILD = "0"
          env.GIT_COMMIT = sh(returnStdout: true, script: "git rev-parse HEAD").trim()
          env.SIM_ENVIRONMENTS = sh(returnStdout: true, script: "./Jenkins/get-assets.sh Assets/External/Environments ${S3_DOWNLOAD_HOST} environment 1").trim()
          env.SIM_VEHICLES = sh(returnStdout: true, script: "./Jenkins/get-assets.sh Assets/External/Vehicles ${S3_DOWNLOAD_HOST} vehicle 1").trim()
          env.SIM_SENSORS = ""
        } // script

        sh label:"SIMULATOR env vars", script:"printenv | grep -E 'SIMULATOR|^SIM_' | sort"
      }
    }

    stage("Checkout NPCs") {
      steps {
        script {
          def npcs = env.SIMULATOR_NPCS_REPOS.split(',')
          for (int i=0; i<npcs.size(); i++) {
            def npc = npcs[i]
            checkout([
              $class: "GitSCM",
              branches: [[name: "refs/heads/master"]],
              browser: [$class: "GitLab", repoUrl: "https://${GITLAB_HOST}/HDRP/NPC/${npc}", version: env.GITLAB_VERSION],
              extensions: [
                [$class: "RelativeTargetDirectory", relativeTargetDir: "Assets/External/NPCs/${npc}"],
                [$class: "LocalBranch"],
                [$class: "GitLFSPull"]
              ],
              userRemoteConfigs: [[
                credentialsId: "auto-gitlab",
                url: "git@${GITLAB_HOST}:HDRP/NPC/${npc}.git"
              ]]
            ])
          }
        } // script
      }
    }

    stage("Docker") {
      environment {
        DOCKER = credentials("Jenkins-Gitlab")
      }
      steps {
        dir("Jenkins") {
          sh """
            docker login -u ${DOCKER_USR} -p ${DOCKER_PSW} ${GITLAB_HOST}:4567
            docker-compose build build-simulator
            docker-compose push build-simulator
          """
        }
      }
    }

    stage("Check") {
      steps {
        dir("Jenkins") {
          sh "UID=`id -u` docker-compose run --rm build-simulator check"
        }
      }
      post {
        success {
          archiveArtifacts "*-check-${OUTPUT_SUFFIX}.html"
        }
      }
    }

    stage("Test") {
      steps {
        dir("Jenkins") {
          sh "UID=`id -u` docker-compose run --rm build-simulator test"
        }
      }
      post {
        success {
          xunit([NUnit3(pattern: "*-test-${OUTPUT_SUFFIX}.xml", deleteOutputFiles: true)])
        }
      }
    }

    stage("Windows") {

      steps {
        dir("Jenkins") {
          withCredentials([file(credentialsId: "LGSVL_CODE_SIGNING_FILE", variable: "CODE_SIGNING_FILE")]) {
            sh "UID=`id -u` docker-compose run --rm build-simulator windows"
          }
        }
      }

      post {
        success {
          archiveArtifacts "*-windows64-${OUTPUT_SUFFIX}.zip"
        }
      }

    } // Windows

    stage("Linux") {

      steps {
        dir("Jenkins") {
          sh "UID=`id -u` docker-compose run --rm build-simulator linux"
        }
        sh """
          ZIP=`basename *-linux64-${OUTPUT_SUFFIX}.zip`
          NORUNNER=`echo \$ZIP | sed 's/\\.zip\$/-norunner.zip/g'`
          mv \$ZIP \$NORUNNER
        """
      }

      post {
        success {
          archiveArtifacts "*-linux64-${OUTPUT_SUFFIX}-norunner.zip"
        }
      }

    } // Linux

    stage("bundleScenariosRunner") {
      steps {
        dir("Jenkins") {
          sh """
            if ! docker pull ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG; then
              echo "ABORT: cannot pull ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG"
              exit 1
            fi
            TEMP_CONT=`docker create ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG --name scenarios-runner-tmp`
            if ! docker cp \$TEMP_CONT:/usr/share/scenarios-runner/scripts .; then
              echo "ABORT: ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG doesn't have /usr/share/scenarios-runner/scripts directory"
              docker rm \$TEMP_CONT
              exit 1
            fi
            if ! docker cp \$TEMP_CONT:/etc/wise-image-info.source .; then
              echo "ABORT: ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG doesn't have /etc/wise-image-info.source file"
              docker rm \$TEMP_CONT
              exit 1
            fi
            docker rm \$TEMP_CONT

            rm -rf dist
            mkdir -p dist/docker
            DST_TAG="lgsvl/simulator-scenarios-runner:simulator-build__${OUTPUT_SUFFIX}"
            DST_TARBALL=\$(echo \$DST_TAG | tr ':/' '-')

            docker tag ${GITLAB_HOST}:4567/\$SCENARIOS_RUNNER_DOCKER_TAG \$DST_TAG

            echo "INFO: saving docker image \$DST_TAG to dist/docker/\$DST_TARBALL.tar"
            docker save \$DST_TAG > dist/docker/\$DST_TARBALL.tar

            cp scripts/install-testcase-runtime.sh scripts/scenario_runner.sh dist

            echo "INFO: update the default SCENARIO_RUNNER_IMAGE in scenario_runner.sh from whatever was there (probably "auto-gitlab.lgsvl.net:4567/hdrp/scenarios/runner:dev") to \$DST_TAG"
            sed -i "s#^SCENARIO_RUNNER_IMAGE_DEFAULT=.*#SCENARIO_RUNNER_IMAGE_DEFAULT=\$DST_TAG#g" dist/scenario_runner.sh

            ZIP=../*-linux64-${OUTPUT_SUFFIX}-norunner.zip

            unzip -o \$ZIP
            UNZIP=`basename \$ZIP | sed 's/-norunner\\.zip\$//g'`
            echo "INFO: bundling simulator from \$UNZIP with scenarios runner from docker image \$SCENARIOS_RUNNER_DOCKER_TAG:"
            cat wise-image-info.source

            dist/install-testcase-runtime.sh \$UNZIP copy
            zip --symlinks -r ../\$UNZIP.zip \$UNZIP
            rm -rvf dist \$UNZIP/
            rm -f wise-image-info.source
          """
        }
      }
      post {
        success {
          archiveArtifacts "*-linux64-${OUTPUT_SUFFIX}.zip"
        }
      }
    }

    stage("uploadECR") {
      steps {
        dir("Jenkins") {
          sh "echo Using credentials ${WISE_AWS_ECR_CREDENTIALS_ID}"
          withCredentials([[credentialsId: "${WISE_AWS_ECR_CREDENTIALS_ID}", accessKeyVariable: 'AWS_ACCESS_KEY_ID', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY', $class: 'AmazonWebServicesCredentialsBinding']]) {
            sh """
              DOCKER_REGISTRY="${WISE_AWS_ECR_ACCOUNT_ID}.dkr.ecr.${WISE_AWS_ECR_REGION}.amazonaws.com"
              DOCKER_REPO="wise/simulator"
              DOCKER_TAG="version__\${OUTPUT_SUFFIX}_${JENKINS_BUILD_ID}"

              docker-compose pull aws-cli
              if ! UID=`id -u` docker-compose run --rm aws-cli ecr get-login-password --region $WISE_AWS_ECR_REGION | docker login --username AWS --password-stdin \$DOCKER_REGISTRY; then
                echo "ABORT: bad AWS credentials?"
                exit 1
              fi
              if ! UID=`id -u` docker-compose run --rm aws-cli ecr create-repository --repository-name \$DOCKER_REPO --region $WISE_AWS_ECR_REGION; then
                echo "INFO: aws-cli ecr create-repository --repository-name \$DOCKER_REPO --region $WISE_AWS_ECR_REGION failed - assuming that it's because the repo already exists in ECR"
              fi

              cd ../Docker
              cp -al ../*-linux64-${OUTPUT_SUFFIX}-norunner.zip .
              docker build --pull --no-cache \
                  --build-arg "simulator_zipfile=*-linux64-${OUTPUT_SUFFIX}-norunner.zip" \
                  --build-arg image_git_describe=\$(git describe --always --tags) \
                  --build-arg image_uuidgen=\$(uuidgen) \
                  -t \$DOCKER_REGISTRY/\$DOCKER_REPO:\$DOCKER_TAG .
              docker push \$DOCKER_REGISTRY/\$DOCKER_REPO:\$DOCKER_TAG
              rm -fv *-linux64-${OUTPUT_SUFFIX}-norunner.zip

              docker image rm \
                \$DOCKER_REGISTRY/\$DOCKER_REPO:\$DOCKER_TAG
              docker container prune -f
              docker volume prune -f
              docker image prune -f
            """
          }
        }
      }
    } // uploadECR
  } // stages

  post {
    failure {
      mail to: "${SIMULATOR_RELEASE_EMAILS}", subject: "Failed ${OUTPUT_SUFFIX} release build", body: "Failed ${OUTPUT_SUFFIX} release build: ${BUILD_URL}"
    }
    success {
      mail to: "${SIMULATOR_RELEASE_EMAILS}", subject: "Finished ${OUTPUT_SUFFIX} release build", body: "Finished ${OUTPUT_SUFFIX} release build: ${BUILD_URL}"
    }
    always {
        sh script:"zip logs-${OUTPUT_SUFFIX}.zip *.log || true", label:"Archive log files"
        archiveArtifacts artifacts:"logs*.zip", allowEmptyArchive:true
    }
  }

}
